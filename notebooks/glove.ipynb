{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.expanduser('~/work/data/data.pkl'), \"rb\") as input_file:\n",
    "    data1 = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.expanduser('~/work/data/vocabulary.pkl'), \"rb\") as input_file:\n",
    "    vocabulary = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2idx = {tok:i for i, tok in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glovetokens = {}\n",
    "i = 0\n",
    "with open(path.expanduser('~/work/test/lftm/glove.6B.50d.txt'),\"r+\") as f:\n",
    "    while True:\n",
    "        vec = f.readline()\n",
    "        if not vec:\n",
    "            break\n",
    "        w = vec[:vec.index(' ')]\n",
    "        if w not in glovetokens:\n",
    "            glovetokens[w] = i\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.expanduser('~/work/data/glovetokens.pkl'), 'wb') as output:\n",
    "    pickle.dump(glovetokens, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2remove = {}\n",
    "for t in vocabulary:\n",
    "    if t not in glovetokens:\n",
    "        tok2remove[t] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tokens(x):\n",
    "    return ' '.join(['' if t in tok2remove else t for t in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['transcript'] = data1['transcript'].apply(lambda x: remove_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(path.expanduser('~/work/test/lftm/data.txt'), \"w\")\n",
    "for talk in data1['transcript'].values:\n",
    "    file.write(talk+'\\n') \n",
    "file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
